{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "OVK1TglxOKd4",
        "outputId": "2514c82e-e904-4a6e-8377-8578927e3611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models, \\nthat represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models. \\nA kernel method is equivalent to the corresponding linear method operating on the feature space defined by the kernel function. \\nMany kernel methods do not require us to explicitly compute ˚(x), but instead we will compute the n nGram matrix using the kernel function (;). \\nIn other words, we are able to build classifiers in arbitrarily complex D feature space, but we do not have to compute any element of that space explicitly.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
        "'''In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models, \n",
        "that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models. \n",
        "A kernel method is equivalent to the corresponding linear method operating on the feature space defined by the kernel function. \n",
        "Many kernel methods do not require us to explicitly compute ˚(x), but instead we will compute the n nGram matrix using the kernel function (;). \n",
        "In other words, we are able to build classifiers in arbitrarily complex D feature space, but we do not have to compute any element of that space explicitly.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
        "from sklearn import datasets\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "# Load iris dataset\n",
        "iris = datasets.load_iris()\n",
        "# Define X and y\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "# Create SVM classifier based on polynomial kernel\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel='poly', degree=3, gamma='auto'))\n",
        "# Fit the classifier to the data\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "OvqthyyROw6z",
        "outputId": "02e9ffcb-68f4-4d1d-d067-0582681db617"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(gamma='auto', kernel='poly'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
        "'''The value of epsilon in SVR controls the width of the ε-insensitive zone used to fit the training data. The bigger epsilon, the fewer support vectors are selected. \n",
        "If epsilon is zero, we can expect overfitting. Increasing epsilon can lead to a decrease in the number of support vectors used to construct the regression function.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1f3LRC-hPGky",
        "outputId": "7a2f9bf5-b127-4815-82b7-dfa494413449"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The value of epsilon in SVR controls the width of the ε-insensitive zone used to fit the training data. The bigger epsilon, the fewer support vectors are selected. \\nIf epsilon is zero, we can expect overfitting. Increasing epsilon can lead to a decrease in the number of support vectors used to construct the regression function.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
        "and provide examples of when you might want to increase or decrease its value?'''\n",
        "'''The kernel function is used to transform the input data into a higher-dimensional space where it can be separated by a hyperplane. \n",
        "The choice of kernel function can affect the performance of SVR. For example, if the data is linearly separable, \n",
        "then a linear kernel function can be used. If the data is not linearly separable, then a non-linear kernel function such as Radial Basis Function (RBF) can be used.\n",
        "1) C Parameter: The C parameter trades off correct classification of training examples against maximization of the decision function’s margin. \n",
        "A smaller value of C creates a wider margin but more margin violations. A larger value of C creates a narrower margin but fewer margin violations.\n",
        "2) Epsilon Parameter: The epsilon parameter determines the width of the epsilon-insensitive zone around each prediction target. The larger the value of epsilon, the larger the insensitive zone.\n",
        "3) Gamma Parameter: The gamma parameter defines how far the influence of a single training example reaches with low values meaning ‘far’ and high values meaning ‘close’. \n",
        "The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors. \n",
        "If gamma is large, then it will consider only nearby points for classification while if gamma is small, then it will consider far away points also for classification.\n",
        "Here are some examples when you might want to increase or decrease each parameter:\n",
        "1) Kernel Function: If your data is linearly separable, then you might want to use a linear kernel function. \n",
        "If your data is not linearly separable, then you might want to use a non-linear kernel function such as RBF.\n",
        "2) C Parameter: If you want to create a wider margin but more margin violations, then you might want to decrease C. \n",
        "If you want to create a narrower margin but fewer margin violations, then you might want to increase C.\n",
        "3) Epsilon Parameter: If you want to increase the width of the insensitive zone around each prediction target, then you might want to increase epsilon. \n",
        "If you want to decrease the width of the insensitive zone around each prediction target, then you might want to decrease epsilon.\n",
        "4) Gamma Parameter: If you want to consider only nearby points for classification, then you might want to increase gamma. \n",
        "If you want to consider far away points also for classification, then you might want to decrease gamma.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MchZokzpPYqI",
        "outputId": "72e842fa-bf7b-4a76-dc52-91131be6b60e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The kernel function is used to transform the input data into a higher-dimensional space where it can be separated by a hyperplane. \\nThe choice of kernel function can affect the performance of SVR. For example, if the data is linearly separable, \\nthen a linear kernel function can be used. If the data is not linearly separable, then a non-linear kernel function such as Radial Basis Function (RBF) can be used.\\n1) C Parameter: The C parameter trades off correct classification of training examples against maximization of the decision function’s margin. \\nA smaller value of C creates a wider margin but more margin violations. A larger value of C creates a narrower margin but fewer margin violations.\\n2) Epsilon Parameter: The epsilon parameter determines the width of the epsilon-insensitive zone around each prediction target. The larger the value of epsilon, the larger the insensitive zone.\\n3) Gamma Parameter: The gamma parameter defines how far the influence of a single training example reaches with low values meaning ‘far’ and high values meaning ‘close’. \\nThe gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors. \\nIf gamma is large, then it will consider only nearby points for classification while if gamma is small, then it will consider far away points also for classification.\\nHere are some examples when you might want to increase or decrease each parameter:\\n1) Kernel Function: If your data is linearly separable, then you might want to use a linear kernel function. \\nIf your data is not linearly separable, then you might want to use a non-linear kernel function such as RBF.\\n2) C Parameter: If you want to create a wider margin but more margin violations, then you might want to decrease C. \\nIf you want to create a narrower margin but fewer margin violations, then you might want to increase C.\\n3) Epsilon Parameter: If you want to increase the width of the insensitive zone around each prediction target, then you might want to increase epsilon. \\nIf you want to decrease the width of the insensitive zone around each prediction target, then you might want to decrease epsilon.\\n4) Gamma Parameter: If you want to consider only nearby points for classification, then you might want to increase gamma. \\nIf you want to consider far away points also for classification, then you might want to decrease gamma.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Assignment:\n",
        "- Import the necessary libraries and load the dataseg\n",
        "- Split the dataset into training and testing setZ\n",
        "- Preprocess the data using any technique of your choice (e.g. scaling, normaliMation)\n",
        "- Create an instance of the SVC classifier and train it on the training data\n",
        "- Use the trained classifier to predict the labels of the testing data\n",
        "- Evaluate the performance of the classifier using any metric of your choice \n",
        "(e.g. accuracy,\n",
        "precision, recall, F1-score)\n",
        "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance.\n",
        "- Train the tuned classifier on the entire dataseg\n",
        "- Save the trained classifier to a file for future use."
      ],
      "metadata": {
        "id": "QShuqNrtQhKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle"
      ],
      "metadata": {
        "id": "8dxfTjGlRiSy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load dataset\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']"
      ],
      "metadata": {
        "id": "tbj-P5ykRsQf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yvoK4RUuYUxI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocess the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "WacOtGmGYYDm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create instance of SVC classifier and train it on training data\n",
        "clf = SVC(kernel='rbf', C=1, gamma='auto')\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DD5jAMhcYa0O",
        "outputId": "53686014-3495-4c5a-b5dc-317f45d948ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, gamma='auto')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Use trained classifier to predict labels of testing data\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "uY_0xOrwYc_n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate performance of classifier using accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVWAOvY_Yhcf",
        "outputId": "38687029-58f0-45de-9126-c6dda37530f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7337662337662337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tune hyperparameters of SVC classifier using GridSearchCV to improve performance\n",
        "parameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
        "grid_search = GridSearchCV(clf, parameters, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "print('Best parameters:', best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7wq9w2gYkTP",
        "outputId": "93e1d58c-06be-409c-9400-ca440359e608"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train tuned classifier on entire dataset\n",
        "clf_tuned = SVC(kernel=best_params['kernel'], C=best_params['C'], gamma=best_params['gamma'])\n",
        "clf_tuned.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "syOSaTrzYmvn",
        "outputId": "1fe972c7-541f-488d-a6d4-ba3ca3485eb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save trained classifier to file\n",
        "pickle.dump(clf_tuned,open('/content/Model/diabetes_classifier.pkl','wb'))\n",
        "model=pickle.load(open('/content/Model/diabetes_classifier.pkl','rb'))"
      ],
      "metadata": {
        "id": "S1bjq-C2YtD3"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}