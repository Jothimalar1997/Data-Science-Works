{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the featur engineering process and handles the missing values.Design a pipeline that includes the following steps.Use an automated feature selection method to identify the important features in the dataset\n",
        "\n",
        "Create a numerical pipeline that includes the following steps:\n",
        "\n",
        "Impute the missing values in the numerical columns using the mean of the column values\n",
        "\n",
        "Scale the numerical columns using standardscaler\n",
        "\n",
        "Create a categorical pipeline that includes the following steps:\n",
        "Impute the missing values in the categorical columns using the most frequent value of the column\n",
        "\n",
        "One-hot encode the categorical columns\n",
        "\n",
        "Combine the numerical and categorical pipelines using a ColumnTransformer\n",
        "\n",
        "Use a Random Forest Classifier to build the final model\n",
        "\n",
        "Evaluate the accuracy of the model on the test dataset\n",
        "\n",
        "Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
        "each step.\n",
        "You should also provide an #nterpretat#on of the results and suggest possible improvements for\n",
        "the pipeline"
      ],
      "metadata": {
        "id": "VYtZaagMK3Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# load data\n",
        "data = pd.read_csv('data.csv')     ## Defined only for the purpose of code snippet\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# automated feature selection\n",
        "selector = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
        "selector.fit(X, y)\n",
        "X = selector.transform(X)\n",
        "\n",
        "# define numeric pipeline\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# define categorical pipeline\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# combine numeric and categorical pipelines\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, selector.get_support(indices=True)),\n",
        "    ('cat', categorical_transformer, ~selector.get_support(indices=True))\n",
        "])\n",
        "\n",
        "# add classifier to pipeline\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                       ('classifier', RandomForestClassifier(n_estimators=100))])\n",
        "\n",
        "# fit the model and make predictions\n",
        "pipe.fit(X, y)\n",
        "y_pred = pipe.predict(X)\n",
        "\n",
        "# evaluate the model\n",
        "acc = accuracy_score(y, y_pred)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "suSRsV8SLCyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insights:\n",
        "This solution first uses an automated feature selection method (SelectFromModel) to identify the important features in the dataset based on their importance scores from a Random Forest model. The selected features are then used to create a ColumnTransformer that applies different preprocessing pipelines to the numerical and categorical parts of the data.\n",
        "\n",
        "For the numerical part, missing values are imputed with the mean of the column values (SimpleImputer), and then the values are scaled to have zero mean and unit variance (StandardScaler). For the categorical part, missing values are imputed with the most frequent value of the column (SimpleImputer), and then the categorical variables are one-hot encoded to represent each level as a binary indicator variable (OneHotEncoder).\n",
        "\n",
        "The final preprocessed data is then fed into a Random Forest classifier (RandomForestClassifier) to build the model. The accuracy of the model is evaluated using the original target values and the predicted values.\n",
        "\n",
        "Possible improvements to this pipeline include trying different feature selection methods or hyperparameters for the preprocessing and modeling steps, using different imputation strategies or scaling methods, and testing different classifiers or ensemble methods. Additionally, domain knowledge and data exploration may suggest other ways to engineer the features or handle missing values."
      ],
      "metadata": {
        "id": "pZPO1OVsLIH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the Iris dataset and evaluate its accuracy."
      ],
      "metadata": {
        "id": "koD1tUeoMHbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Define the column transformer for scaling numeric columns and one-hot encoding categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), [0, 1, 2, 3]),\n",
        "        ('cat', OneHotEncoder(), [])\n",
        "    ])\n",
        "\n",
        "# Define the random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the logistic regression classifier\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_clf = VotingClassifier(estimators=[('rf', rf), ('lr', lr)], voting='hard')\n",
        "\n",
        "# Define the pipeline\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                       ('voting_clf', voting_clf)])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the accuracy of the pipeline on the testing data\n",
        "y_pred = pipe.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJEdMidHYDAR",
        "outputId": "fe2f0cf8-3f3e-47ec-a90f-f3617c3fca30"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    }
  ]
}