{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7vamu8tjq6Y3",
        "outputId": "684cee90-82ba-4665-e880-30f768d67657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bayes’ theorem is a mathematical formula that calculates the probability of an event, based on prior knowledge of conditions that might be related to the event. \\nIt can be used to revise or update probabilities given new evidence.\\nBayes’ theorem has many applications, including Bayesian inference, a particular approach to statistical inference.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Q1. What is Bayes' theorem?\n",
        "'''Bayes’ theorem is a mathematical formula that calculates the probability of an event, based on prior knowledge of conditions that might be related to the event. \n",
        "It can be used to revise or update probabilities given new evidence.\n",
        "Bayes’ theorem has many applications, including Bayesian inference, a particular approach to statistical inference.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. What is the formula for Bayes' theorem?\n",
        "'''The formula for Bayes’ theorem is:\n",
        "P(A|B) = P(B|A) * P(A) / P(B)\n",
        "where P(A|B) is the probability of A given B, P(B|A) is the probability of B given A, P(A) is the prior probability of A, and P(B) is the prior probability of B.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oEw-ZycLr_dF",
        "outputId": "021d440d-6856-4ff0-9878-bdbc4fe25293"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The formula for Bayes’ theorem is:\\nP(A|B) = P(B|A) * P(A) / P(B)\\nwhere P(A|B) is the probability of A given B, P(B|A) is the probability of B given A, P(A) is the prior probability of A, and P(B) is the prior probability of B.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. How is Bayes' theorem used in practice?\n",
        "'''Bayes’ theorem has many applications in practice, including Bayesian inference, a particular approach to statistical inference. \n",
        "It can also be used in machine learning for classification problems. \n",
        "For example, it can be used to classify emails as spam or not spam.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TY1L8yLttAdG",
        "outputId": "8b5de0d0-21a2-4053-b9af-e8e678e947d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bayes’ theorem has many applications in practice, including Bayesian inference, a particular approach to statistical inference. \\nIt can also be used in machine learning for classification problems. \\nFor example, it can be used to classify emails as spam or not spam.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "'''Bayes’ theorem is based on conditional probability. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. \n",
        "The formula for Bayes’ theorem includes conditional probabilities:\n",
        "P(A|B) = P(B|A) * P(A) / P(B)\n",
        "where P(A|B) is the probability of A given B, P(B|A) is the probability of B given A.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4cTmhz74tHOP",
        "outputId": "6cbb4049-29d8-4b4a-a2c3-214bca36e3a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bayes’ theorem is based on conditional probability. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. \\nThe formula for Bayes’ theorem includes conditional probabilities:\\nP(A|B) = P(B|A) * P(A) / P(B)\\nwhere P(A|B) is the probability of A given B, P(B|A) is the probability of B given A.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "'''There are three types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes.\n",
        "Gaussian Naive Bayes is used when the features are continuous variables that can be modeled using a Gaussian distribution. \n",
        "Multinomial Naive Bayes is used when the features are discrete counts (such as word counts). \n",
        "ernoulli Naive Bayes is used when the features are binary (such as presence or absence of a feature).\n",
        "The choice of which type of Naive Bayes classifier to use depends on the nature of the problem and the type of data being analyzed.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uqsEmdIvtfq2",
        "outputId": "9506a7b5-2a40-4a9b-af8b-9e2f51518977"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are three types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes.\\nGaussian Naive Bayes is used when the features are continuous variables that can be modeled using a Gaussian distribution. \\nMultinomial Naive Bayes is used when the features are discrete counts (such as word counts). \\nernoulli Naive Bayes is used when the features are binary (such as presence or absence of a feature).\\nThe choice of which type of Naive Bayes classifier to use depends on the nature of the problem and the type of data being analyzed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "A 3 3 4 4 3 3 3\n",
        "B 2 2 1 2 2 2 3\n",
        "## Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
      ],
      "metadata": {
        "id": "kwHeFlfptywO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''To predict which class the new instance belongs to using Naive Bayes, we need to calculate the posterior probability of each class given the feature values of the new instance. \n",
        "The class with the highest posterior probability is the predicted class.\n",
        "The posterior probability of each class can be calculated using Bayes’ theorem:\n",
        "P(A|X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) / P(X1=3,X2=4) P(B|X1=3,X2=4) = P(X1=3,X2=4|B) * P(B) / P(X1=3,X2=4)\n",
        "where P(A|X1=3,X2=4) is the posterior probability of class A given X1=3 and X2=4, P(X1=3,X2=4|A) is the likelihood of X1=3 and X2=4 given class A, \n",
        "P(A) is the prior probability of class A, and P(X1=3,X2=4) is the marginal probability of X1=3 and X2=4.\n",
        "Using the table provided, we can calculate these probabilities as follows:\n",
        "P(X1=3,X2=4|A) = 4/17 * 3/17 = 12/289 P(X1=3,X2=4|B) = 1/9 * 3/9 = 1/27 P(A) = 0.5 P(B) = 0.5 P(X1=3,X2=4) = P(X1=3,X2=4|A)*P(A) + P(X1=3,X2=4|B)*P(B) = (12/289)*0.5 + (1/27)*0.5 = 0.022\n",
        "Therefore,\n",
        "P(A|X1=3,X2=4) = (12/289)*0.5 / 0.022 ≈ 0.65 P(B|X1=3,X2=4) = (1/27)*0.5 / 0.022 ≈ 0.35\n",
        "So Naive Bayes would predict that the new instance belongs to class A.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "_m0t1rAptxs_",
        "outputId": "2752b2a7-557f-45b0-f050-005f8f1ed299"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To predict which class the new instance belongs to using Naive Bayes, we need to calculate the posterior probability of each class given the feature values of the new instance. \\nThe class with the highest posterior probability is the predicted class.\\nThe posterior probability of each class can be calculated using Bayes’ theorem:\\nP(A|X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) / P(X1=3,X2=4) P(B|X1=3,X2=4) = P(X1=3,X2=4|B) * P(B) / P(X1=3,X2=4)\\nwhere P(A|X1=3,X2=4) is the posterior probability of class A given X1=3 and X2=4, P(X1=3,X2=4|A) is the likelihood of X1=3 and X2=4 given class A, \\nP(A) is the prior probability of class A, and P(X1=3,X2=4) is the marginal probability of X1=3 and X2=4.\\nUsing the table provided, we can calculate these probabilities as follows:\\nP(X1=3,X2=4|A) = 4/17 * 3/17 = 12/289 P(X1=3,X2=4|B) = 1/9 * 3/9 = 1/27 P(A) = 0.5 P(B) = 0.5 P(X1=3,X2=4) = P(X1=3,X2=4|A)*P(A) + P(X1=3,X2=4|B)*P(B) = (12/289)*0.5 + (1/27)*0.5 = 0.022\\nTherefore,\\nP(A|X1=3,X2=4) = (12/289)*0.5 / 0.022 ≈ 0.65 P(B|X1=3,X2=4) = (1/27)*0.5 / 0.022 ≈ 0.35\\nSo Naive Bayes would predict that the new instance belongs to class A.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}