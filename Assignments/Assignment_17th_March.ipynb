{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CTxpBbpYM6OY",
        "outputId": "48b88ec7-c565-4ad6-afac-af15c54ce1f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Missing data, or missing values, occur when you don’t have data stored for certain variables or participants. \\nData can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons.\\nMissing data are problematic because, depending on the type, they can sometimes cause sampling bias. \\nThis means your results may not be generalizable outside of your study because your data come from an unrepresentative sample.\\nThe k-NN algorithm can ignore a column from a distance measure when a value is missing. Naive Bayes can also support missing values when making a prediction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
        "'''Missing data, or missing values, occur when you don’t have data stored for certain variables or participants. \n",
        "Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons.\n",
        "Missing data are problematic because, depending on the type, they can sometimes cause sampling bias. \n",
        "This means your results may not be generalizable outside of your study because your data come from an unrepresentative sample.\n",
        "The k-NN algorithm can ignore a column from a distance measure when a value is missing. Naive Bayes can also support missing values when making a prediction.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
        "'''1. Delete the Data\n",
        "The easiest method is to just simply delete the whole training examples where one or several columns have null entries.\n",
        "2. Imputing Averages\n",
        "The next method is to assign some average value (mean, median, or mode) to the null entries.\n",
        "3. Assign Random values:\n",
        "We can assign random values related to the dataset in the place of missing value.'''\n",
        "import seaborn as sns\n",
        "data=sns.load_dataset('titanic')\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozQzF2lSN_ok",
        "outputId": "81186dba-e993-48c8-a6d4-3e86d93f79ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived         0\n",
              "pclass           0\n",
              "sex              0\n",
              "age            177\n",
              "sibsp            0\n",
              "parch            0\n",
              "fare             0\n",
              "embarked         2\n",
              "class            0\n",
              "who              0\n",
              "adult_male       0\n",
              "deck           688\n",
              "embark_town      2\n",
              "alive            0\n",
              "alone            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEC31_j3Qkdy",
        "outputId": "f4d2b24e-bece-409c-c9c6-ab68dea38dcd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## (i) dropping rows which have missing values:\n",
        "data.dropna() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2WqwbTaJP9er",
        "outputId": "a1805825-ee92-4882-c388-2ebce46055db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
              "1           1       1  female  38.0      1      0  71.2833        C  First   \n",
              "3           1       1  female  35.0      1      0  53.1000        S  First   \n",
              "6           0       1    male  54.0      0      0  51.8625        S  First   \n",
              "10          1       3  female   4.0      1      1  16.7000        S  Third   \n",
              "11          1       1  female  58.0      0      0  26.5500        S  First   \n",
              "..        ...     ...     ...   ...    ...    ...      ...      ...    ...   \n",
              "871         1       1  female  47.0      1      1  52.5542        S  First   \n",
              "872         0       1    male  33.0      0      0   5.0000        S  First   \n",
              "879         1       1  female  56.0      0      1  83.1583        C  First   \n",
              "887         1       1  female  19.0      0      0  30.0000        S  First   \n",
              "889         1       1    male  26.0      0      0  30.0000        C  First   \n",
              "\n",
              "       who  adult_male deck  embark_town alive  alone  \n",
              "1    woman       False    C    Cherbourg   yes  False  \n",
              "3    woman       False    C  Southampton   yes  False  \n",
              "6      man        True    E  Southampton    no   True  \n",
              "10   child       False    G  Southampton   yes  False  \n",
              "11   woman       False    C  Southampton   yes   True  \n",
              "..     ...         ...  ...          ...   ...    ...  \n",
              "871  woman       False    D  Southampton   yes  False  \n",
              "872    man        True    B  Southampton    no   True  \n",
              "879  woman       False    C    Cherbourg   yes  False  \n",
              "887  woman       False    B  Southampton   yes   True  \n",
              "889    man        True    C    Cherbourg   yes   True  \n",
              "\n",
              "[182 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-114d9d67-e650-4afe-bfa5-1cad4c510e18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>E</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>child</td>\n",
              "      <td>False</td>\n",
              "      <td>G</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>D</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>B</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>B</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>182 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-114d9d67-e650-4afe-bfa5-1cad4c510e18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-114d9d67-e650-4afe-bfa5-1cad4c510e18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-114d9d67-e650-4afe-bfa5-1cad4c510e18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## (ii) Imputing mean value:\n",
        "data['age_mean']=data['age'].fillna(data['age'].mean())\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ponv-3dYQuOy",
        "outputId": "52b2427c-3d54-411c-f3e2-a23dce8e6ea5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
              "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
              "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
              "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
              "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
              "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
              "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
              "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
              "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
              "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
              "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
              "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
              "\n",
              "       who  adult_male deck  embark_town alive  alone   age_mean  \n",
              "0      man        True  NaN  Southampton    no  False  22.000000  \n",
              "1    woman       False    C    Cherbourg   yes  False  38.000000  \n",
              "2    woman       False  NaN  Southampton   yes   True  26.000000  \n",
              "3    woman       False    C  Southampton   yes  False  35.000000  \n",
              "4      man        True  NaN  Southampton    no   True  35.000000  \n",
              "..     ...         ...  ...          ...   ...    ...        ...  \n",
              "886    man        True  NaN  Southampton    no   True  27.000000  \n",
              "887  woman       False    B  Southampton   yes   True  19.000000  \n",
              "888  woman       False  NaN  Southampton    no  False  29.699118  \n",
              "889    man        True    C    Cherbourg   yes   True  26.000000  \n",
              "890    man        True  NaN   Queenstown    no   True  32.000000  \n",
              "\n",
              "[891 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bf5e7d6-7665-4f12-bbc0-4bf396edcb53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "      <th>age_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>38.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>Second</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>B</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>29.699118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf5e7d6-7665-4f12-bbc0-4bf396edcb53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bf5e7d6-7665-4f12-bbc0-4bf396edcb53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bf5e7d6-7665-4f12-bbc0-4bf396edcb53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Filling random value:\n",
        "data['age_mean']=data['age'].fillna(23)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KmyCKw6fRNlS",
        "outputId": "4f0a7faa-09aa-4b14-da77-de8c5cb9d711"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
              "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
              "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
              "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
              "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
              "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
              "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
              "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
              "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
              "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
              "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
              "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
              "\n",
              "       who  adult_male deck  embark_town alive  alone  age_mean  \n",
              "0      man        True  NaN  Southampton    no  False      22.0  \n",
              "1    woman       False    C    Cherbourg   yes  False      38.0  \n",
              "2    woman       False  NaN  Southampton   yes   True      26.0  \n",
              "3    woman       False    C  Southampton   yes  False      35.0  \n",
              "4      man        True  NaN  Southampton    no   True      35.0  \n",
              "..     ...         ...  ...          ...   ...    ...       ...  \n",
              "886    man        True  NaN  Southampton    no   True      27.0  \n",
              "887  woman       False    B  Southampton   yes   True      19.0  \n",
              "888  woman       False  NaN  Southampton    no  False      23.0  \n",
              "889    man        True    C    Cherbourg   yes   True      26.0  \n",
              "890    man        True  NaN   Queenstown    no   True      32.0  \n",
              "\n",
              "[891 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b94168a9-1f4a-4031-b8b7-7156fbcb7f83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "      <th>age_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>Second</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>B</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b94168a9-1f4a-4031-b8b7-7156fbcb7f83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b94168a9-1f4a-4031-b8b7-7156fbcb7f83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b94168a9-1f4a-4031-b8b7-7156fbcb7f83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
        "'''An imbalanced dataset can cause issues when training a model, especially when the dataset is small. \n",
        "A model needs many observations of each target class to be able to generalise adequately, so for small datasets there can simply not be enough minority class observations for the model to learn from. \n",
        "This leads to poor performance on both evaluation and scoring datasets.\n",
        "Imbalanced data can cause issues in understanding the performance of a model. \n",
        "When evaluating performance on imbalanced data, models that only predict well for the majority class will seem to be highly performant when looking at simple metrics such as accuracy, \n",
        "whilst in actuality, the model is performing poorly.\n",
        "In the case of imbalanced data, majority classes dominate over minority classes, causing the machine learning classifiers to be more biased towards majority classes. \n",
        "This causes poor classification of minority classes. Classifiers may even predict all the test data as majority classes.'''"
      ],
      "metadata": {
        "id": "aBIxv_IFRf0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "341747a8-66bf-4faa-a9f9-d015c1f21dbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'An imbalanced dataset can cause issues when training a model, especially when the dataset is small. \\nA model needs many observations of each target class to be able to generalise adequately, so for small datasets there can simply not be enough minority class observations for the model to learn from. \\nThis leads to poor performance on both evaluation and scoring datasets.\\nImbalanced data can cause issues in understanding the performance of a model. \\nWhen evaluating performance on imbalanced data, models that only predict well for the majority class will seem to be highly performant when looking at simple metrics such as accuracy, \\nwhilst in actuality, the model is performing poorly.\\nIn the case of imbalanced data, majority classes dominate over minority classes, causing the machine learning classifiers to be more biased towards majority classes. \\nThis causes poor classification of minority classes. Classifiers may even predict all the test data as majority classes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
        "'''In machine learning, up-sampling and down-sampling are techniques used to resize data sets. \n",
        "Upsampling increases the size of the data set by replicating samples, while downsampling decreases the size of the data set by removing samples.\n",
        "Downsampling reduces dimensionality of the features while losing some information. It saves computation2. Upsampling brings back the resolution to the resolution of previous layer.\n",
        "For example, if you have an imbalanced dataset with a majority class and a minority class, you can use downsampling to reduce the number of samples in the majority class and balance out your dataset and viceversa.'''"
      ],
      "metadata": {
        "id": "EQheaQzZSW17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3cc08d80-cb12-4312-afab-2783e28a01d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In machine learning, up-sampling and down-sampling are techniques used to resize data sets. \\nUpsampling increases the size of the data set by replicating samples, while downsampling decreases the size of the data set by removing samples.\\nDownsampling reduces dimensionality of the features while losing some information. It saves computation2. Upsampling brings back the resolution to the resolution of previous layer.\\nFor example, if you have an imbalanced dataset with a majority class and a minority class, you can use downsampling to reduce the number of samples in the majority class and balance out your dataset and viceversa.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5: What is data Augmentation? Explain SMOTE.\n",
        "'''Data augmentation is a technique used to increase the size of a dataset by creating new data points based on the existing data points. \n",
        "SMOTE (Synthetic Minority Over-sampling Technique) is an algorithm that performs data augmentation by creating synthetic data points based on the original data points. \n",
        "SMOTE can be seen as an advanced version of oversampling, or as a specific algorithm for data augmentation. \n",
        "SMOTE is generally used to address the class imbalance problem in classification tasks.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "S7BmyF5JO29I",
        "outputId": "e13946fc-aa50-428a-e0d5-ccf23aec4137"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data augmentation is a technique used to increase the size of a dataset by creating new data points based on the existing data points. \\nSMOTE (Synthetic Minority Over-sampling Technique) is an algorithm that performs data augmentation by creating synthetic data points based on the original data points. \\nSMOTE can be seen as an advanced version of oversampling, or as a specific algorithm for data augmentation. \\nSMOTE is generally used to address the class imbalance problem in classification tasks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
        "'''Outliers are extreme values that differ from most other data points in a dataset. \n",
        "They can have a big impact on your statistical analyses and skew the results of any hypothesis tests. \n",
        "It’s important to carefully identify potential outliers in your dataset and deal with them in an appropriate manner for accurate results.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "U8_DRT2DPLrY",
        "outputId": "add6bd66-a9b4-4664-f1be-c37a18cb6262"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Outliers are extreme values that differ from most other data points in a dataset. \\nThey can have a big impact on your statistical analyses and skew the results of any hypothesis tests. \\nIt’s important to carefully identify potential outliers in your dataset and deal with them in an appropriate manner for accurate results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
        "'''There are several techniques that can be used to handle missing data in analysis. Some of them are:\n",
        "1) Data Dropping: This technique involves removing observations or features with missing values from the dataframe using the dropna() function.\n",
        "2) Mean/Median Imputation: These replacement strategies involve replacing missing values with the mean or median of the non-missing values.\n",
        "3) Random Sample Imputation: This technique involves replacing missing values with random samples from the non-missing values.\n",
        "4) Multiple Imputation: This technique involves creating multiple imputed datasets and then analyzing each dataset separately before combining them into a single result.\n",
        "5) Measure of central tendency (Mean, Median & Mode): This technique involves replacing missing values with the mean, median or mode of the non-missing values.\n",
        "6) Most probable value (ML Algorithms): This technique involves using machine learning algorithms to predict missing values based on other features in the dataset.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Ge_Ju38-Pj6a",
        "outputId": "c35c1211-b117-422f-de79-6858a7ac65ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several techniques that can be used to handle missing data in analysis. Some of them are:\\n1) Data Dropping: This technique involves removing observations or features with missing values from the dataframe using the dropna() function.\\n2) Mean/Median Imputation: These replacement strategies involve replacing missing values with the mean or median of the non-missing values.\\n3) Random Sample Imputation: This technique involves replacing missing values with random samples from the non-missing values.\\n4) Multiple Imputation: This technique involves creating multiple imputed datasets and then analyzing each dataset separately before combining them into a single result.\\n5) Measure of central tendency (Mean, Median & Mode): This technique involves replacing missing values with the mean, median or mode of the non-missing values.\\n6) Most probable value (ML Algorithms): This technique involves using machine learning algorithms to predict missing values based on other features in the dataset.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
        "to the missing data?'''\n",
        "'''There are several methods to determine if missing data is missing at random or if there is a pattern to the missing data. Here are some of them:\n",
        "1) Mean or Median Imputation: When data is missing at random, we can use list-wise or pair-wise deletion of the missing observations. \n",
        "However, there can be multiple reasons why this may not be the most feasible option. In such cases, we can use mean or median imputation.\n",
        "2) Multivariate Imputation by Chained Equations (MICE): MICE assumes that the missing data are Missing at Random (MAR). \n",
        "It imputes missing values by creating multiple imputations based on a set of regression models.\n",
        "3) Random Forest: Random Forest can be used to determine if there is a pattern to the missing data.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "kTR-LpyzP_vf",
        "outputId": "e3e316aa-05fc-4ca3-ba4d-6f8472c6812b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several methods to determine if missing data is missing at random or if there is a pattern to the missing data. Here are some of them:\\n1) Mean or Median Imputation: When data is missing at random, we can use list-wise or pair-wise deletion of the missing observations. \\nHowever, there can be multiple reasons why this may not be the most feasible option. In such cases, we can use mean or median imputation.\\n2) Multivariate Imputation by Chained Equations (MICE): MICE assumes that the missing data are Missing at Random (MAR). \\nIt imputes missing values by creating multiple imputations based on a set of regression models.\\n3) Random Forest: Random Forest can be used to determine if there is a pattern to the missing data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
        "can use to evaluate the performance of your machine learning model on this imbalanced dataset?'''\n",
        "'''There are several strategies that can be used to evaluate the performance of a machine learning model on an imbalanced dataset. \n",
        "One of the most widely adopted methods is called resampling. \n",
        "It involves removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling). \n",
        "Other techniques include using different performance metrics such as precision, recall, F1 score, and ROC-AUC score.\n",
        "Another technique is to use cost-sensitive learning. This involves assigning different misclassification costs to different classes.\n",
        "For example, misclassifying a positive instance as negative may have a higher cost than misclassifying a negative instance as positive.\n",
        "Ensemble methods such as bagging and boosting can also be used to improve the performance of machine learning models on imbalanced datasets.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "hY3JrEFsQeia",
        "outputId": "3bd3de2e-bf03-4ca4-effb-e560fb734fa0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several strategies that can be used to evaluate the performance of a machine learning model on an imbalanced dataset. \\nOne of the most widely adopted methods is called resampling. \\nIt involves removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling). \\nOther techniques include using different performance metrics such as precision, recall, F1 score, and ROC-AUC score.\\nAnother technique is to use cost-sensitive learning. This involves assigning different misclassification costs to different classes.\\nFor example, misclassifying a positive instance as negative may have a higher cost than misclassifying a negative instance as positive.\\nEnsemble methods such as bagging and boosting can also be used to improve the performance of machine learning models on imbalanced datasets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
        "balance the dataset and down-sample the majority class?'''\n",
        "'''When dealing with an unbalanced dataset, there are several methods that can be employed to balance the dataset and down-sample the majority class. Here are some of them:\n",
        "1) Collect more data\n",
        "2) Change your performance metric\n",
        "3) Resample your dataset\n",
        "4) Generate synthetic samples\n",
        "5) Try different algorithms\n",
        "6)Penalized models\n",
        "Resampling your dataset can be done through under-sampling or over-sampling. \n",
        "With under-sampling, you randomly select a subset of samples from the class with more instances to match the number of samples coming from each class. \n",
        "With over-sampling, you replicate the data of minority class (positive labels) in order to balance the dataset.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "EK7vz_YARCFA",
        "outputId": "479f07aa-5568-4b71-b96d-ce4a0fdce35c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When dealing with an unbalanced dataset, there are several methods that can be employed to balance the dataset and down-sample the majority class. Here are some of them:\\n1) Collect more data\\n2) Change your performance metric\\n3) Resample your dataset\\n4) Generate synthetic samples\\n5) Try different algorithms\\n6)Penalized models\\nResampling your dataset can be done through under-sampling or over-sampling. \\nWith under-sampling, you randomly select a subset of samples from the class with more instances to match the number of samples coming from each class. \\nWith over-sampling, you replicate the data of minority class (positive labels) in order to balance the dataset.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
        "balance the dataset and up-sample the minority class?'''\n",
        "'''There are several methods that can be employed to balance an unbalanced dataset and up-sample the minority class. Here are some of them:\n",
        "1) Use the right evaluation metrics: Applying inappropriate evaluation metrics for model generated using imbalanced data can be dangerous. In this case, accuracy is not a good metric to evaluate our model performance.\n",
        "2) Resample the training set: Resampling techniques can be applied to balance the dataset by either oversampling the minority class or undersampling the majority class.\n",
        "3) Use K-fold Cross-Validation in the Right Way: K-fold cross-validation can be used to evaluate a model with imbalanced data.\n",
        "4) Ensemble Different Resampled Datasets: Ensemble methods can be used to combine different resampled datasets.\n",
        "5) Resample with Different Ratios: Resampling can be done with different ratios of minority class samples to majority class samples.\n",
        "6) Cluster the abundant class: Clustering algorithms can be used to cluster abundant class samples and then select representative samples from each cluster.\n",
        "7) Design Your Models: Designing models that are robust against imbalanced data is another way to handle imbalanced datasets.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QhmE1HqsRTJS",
        "outputId": "7eed95c6-6410-4bd9-ba6c-c5c530f355a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several methods that can be employed to balance an unbalanced dataset and up-sample the minority class. Here are some of them:\\n1) Use the right evaluation metrics: Applying inappropriate evaluation metrics for model generated using imbalanced data can be dangerous. In this case, accuracy is not a good metric to evaluate our model performance.\\n2) Resample the training set: Resampling techniques can be applied to balance the dataset by either oversampling the minority class or undersampling the majority class.\\n3) Use K-fold Cross-Validation in the Right Way: K-fold cross-validation can be used to evaluate a model with imbalanced data.\\n4) Ensemble Different Resampled Datasets: Ensemble methods can be used to combine different resampled datasets.\\n5) Resample with Different Ratios: Resampling can be done with different ratios of minority class samples to majority class samples.\\n6) Cluster the abundant class: Clustering algorithms can be used to cluster abundant class samples and then select representative samples from each cluster.\\n7) Design Your Models: Designing models that are robust against imbalanced data is another way to handle imbalanced datasets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}