{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TOPIC: Understanding Pooling and Padding in CNN"
      ],
      "metadata": {
        "id": "W8hG9lxS6igN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "URoDfgV74rPi",
        "outputId": "2171851e-7d23-4394-ba6a-c37dba78e880"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pooling layers are one of the building blocks of Convolutional Neural Networks (CNNs). \\nThe purpose of pooling is to gradually shrink the representation’s spatial dimension to minimize the number of parameters and computations in the network. \\nPooling layers have several benefits such as:\\n1) Drastic reduction in the number of parameters due to dimensionality reduction, which also translates to lower epoch time.\\n2) Helps in avoiding overfitting by focusing on just dominant features and as a side effect not letting the noise affect the weight updates.\\n3) Translation invariance is also induced into the model due to the above point.\\n4) Feature computation without loss of information.\\n5) Reduction of overfitting.\\n6) Higher generalization capability.\\n7) Computational efficiency.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## 1) Describe the purpose and benefits of pooling in CNN.\n",
        "'''Pooling layers are one of the building blocks of Convolutional Neural Networks (CNNs).\n",
        "The purpose of pooling is to gradually shrink the representation’s spatial dimension to minimize the number of parameters and computations in the network.\n",
        "Pooling layers have several benefits such as:\n",
        "1) Drastic reduction in the number of parameters due to dimensionality reduction, which also translates to lower epoch time.\n",
        "2) Helps in avoiding overfitting by focusing on just dominant features and as a side effect not letting the noise affect the weight updates.\n",
        "3) Translation invariance is also induced into the model due to the above point.\n",
        "4) Feature computation without loss of information.\n",
        "5) Reduction of overfitting.\n",
        "6) Higher generalization capability.\n",
        "7) Computational efficiency.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2) Explain the difference between min pooling and max pooling.\n",
        "'''Max pooling and min pooling are two types of pooling operations used in Convolutional Neural Networks (CNNs).\n",
        "Max pooling calculates the maximum of each block of feature map while Min pooling calculates the minimum of each block of feature map.\n",
        "Average pooling calculates the average of each block of feature map.\n",
        "Max pooling is used to select the most prominent features of the previous feature map while Min pooling is used to select the least important features of the previous feature map.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "z0KTIslk5UQI",
        "outputId": "c4671095-c6ec-4510-f1aa-489b123f0b9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Max pooling and min pooling are two types of pooling operations used in Convolutional Neural Networks (CNNs). \\nMax pooling calculates the maximum of each block of feature map while Min pooling calculates the minimum of each block of feature map. \\nAverage pooling calculates the average of each block of feature map.\\nMax pooling is used to select the most prominent features of the previous feature map while Min pooling is used to select the least important features of the previous feature map.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3) Discuss the concept of padding in CNN and its significance.\n",
        "'''Padding is a technique used in Convolutional Neural Networks (CNNs) that helps in preserving the spatial dimensions of the feature maps and can improve the performance of the model.\n",
        "Padding involves adding extra pixels around the border of the input feature map before convolution.\n",
        "This is done to ensure that the output feature map has the same spatial dimensions as the input feature map.\n",
        "The significance of padding is that it allows more space for the filter to cover the image and it also helps in improving the accuracy of image analysis.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "hW4nLywk5USu",
        "outputId": "e3dc0625-2f8d-466e-ec50-00bd9c7c64d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Padding is a technique used in Convolutional Neural Networks (CNNs) that helps in preserving the spatial dimensions of the feature maps and can improve the performance of the model.\\nPadding involves adding extra pixels around the border of the input feature map before convolution. \\nThis is done to ensure that the output feature map has the same spatial dimensions as the input feature map.\\nThe significance of padding is that it allows more space for the filter to cover the image and it also helps in improving the accuracy of image analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4) Compare and contrast zero-padding and valid-padding in terms of their effects on the output featuce map size.\n",
        "'''In Convolutional Neural Networks (CNNs), padding can be of two types: zero-padding and valid-padding.\n",
        "Zero-padding involves adding zeros to the borders of the input feature map. This is done to ensure that the output feature map has the same spatial dimensions as the input feature map.\n",
        "Valid-padding, on the other hand, does not add any padding to the input feature map. This means that the output feature map will have smaller spatial dimensions than the input feature map.\n",
        "The difference between zero-padding and valid-padding is that zero-padding preserves the spatial dimensions of the input feature map while valid-padding does not.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "QYsBPfMk5933",
        "outputId": "86f2b111-7b1d-4a5c-84f0-d7cefbd2e097"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In Convolutional Neural Networks (CNNs), padding can be of two types: zero-padding and valid-padding.\\nZero-padding involves adding zeros to the borders of the input feature map. This is done to ensure that the output feature map has the same spatial dimensions as the input feature map.\\nValid-padding, on the other hand, does not add any padding to the input feature map. This means that the output feature map will have smaller spatial dimensions than the input feature map.\\nThe difference between zero-padding and valid-padding is that zero-padding preserves the spatial dimensions of the input feature map while valid-padding does not.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOPIC: Exploring LeNet"
      ],
      "metadata": {
        "id": "9zKiWfxZ6n8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1) Provide a breif overview of LeNet-5 architecture.\n",
        "'''LeNet-5 is a convolutional neural network architecture that was created by Yann LeCun in 1998.\n",
        "The architecture consists of two sets of convolutional and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers and finally a softmax classifier.\n",
        "LeNet-5 CNN architecture is made up of 7 layers excluding the input layer. The 7 layers consist of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "9ECO85hx6pFG",
        "outputId": "fdbdfb54-9930-4d29-90f5-01bd866ff214"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LeNet-5 is a convolutional neural network architecture that was created by Yann LeCun in 1998.\\nThe architecture consists of two sets of convolutional and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers and finally a softmax classifier.\\nLeNet-5 CNN architecture is made up of 7 layers excluding the input layer. The 7 layers consist of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2) Describe the key components of LeNet-5 and their respective purposes.\n",
        "'''LeNet-5 consists of 7 layers – alternatingly 2 convolutional and 2 average pooling layers, and then 2 fully connected layers and the output layer with activation function softmax.\n",
        "The architecture consists of two sets of convolutional and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers and finally a softmax classifier.\n",
        "LeNet5 is a small network, it contains the basic modules of deep learning: convolutional layer, pooling layer, and full link layer.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "56yY9TbM7EEi",
        "outputId": "987784b2-845d-4531-fe02-78b9fc0cd605"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LeNet-5 consists of 7 layers – alternatingly 2 convolutional and 2 average pooling layers, and then 2 fully connected layers and the output layer with activation function softmax.\\nThe architecture consists of two sets of convolutional and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers and finally a softmax classifier.\\nLeNet5 is a small network, it contains the basic modules of deep learning: convolutional layer, pooling layer, and full link layer.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3) Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks.\n",
        "'''LeNet-5 was one of the first convolutional neural networks and was designed for handwritten digit recognition.\n",
        "Advantages:\n",
        "1) LeNet-5 is a small network that can be trained quickly and efficiently.\n",
        "2) It is a simple architecture that is easy to understand and implement.\n",
        "3) It has been shown to work well on small image datasets.\n",
        "Limitations:\n",
        "1) LeNet-5 is not suitable for large-scale image classification tasks due to its small size.\n",
        "2) It may not perform well on complex image datasets.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "kLnJsCgO7jaN",
        "outputId": "e230816c-255e-4981-d88a-04853194974b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LeNet-5 was one of the first convolutional neural networks and was designed for handwritten digit recognition.\\nAdvantages:\\n1) LeNet-5 is a small network that can be trained quickly and efficiently.\\n2) It is a simple architecture that is easy to understand and implement.\\n3) It has been shown to work well on small image datasets.\\nLimitations:\\n1) LeNet-5 is not suitable for large-scale image classification tasks due to its small size.\\n2) It may not perform well on complex image datasets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4) Implement LeNet-5 using a deep learning framework of your choice (e.g., TensorFlow, PyTorch) and train it on a publically available dataset (e.g., MNIST). Evaluate its performance and provide insights.\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "# Building the Model Architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(6, kernel_size = (5,5), padding = 'valid', activation='tanh', input_shape = (32,32,3)))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "model.add(Conv2D(16, kernel_size = (5,5), padding = 'valid', activation='tanh'))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120, activation='tanh'))\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1, validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P4NXl7VBaFr",
        "outputId": "57504556-392f-4108-e0ca-95221d3eccaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "391/391 [==============================] - 49s 120ms/step - loss: 1.8433 - accuracy: 0.3471 - val_loss: 1.7343 - val_accuracy: 0.3874\n",
            "Epoch 2/2\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.6953 - accuracy: 0.4062 - val_loss: 1.6316 - val_accuracy: 0.4227\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.6316 - accuracy: 0.4227\n",
            "Test Loss: 1.6315536499023438\n",
            "Test accuracy: 0.4226999878883362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOPIC: Analyzing AlexNet"
      ],
      "metadata": {
        "id": "-k3Uo3zUD7Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1) Present an overview of the AlexNet architecture.\n",
        "'''AlexNet is a convolutional neural network (CNN) architecture that was designed by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton.\n",
        "It won the ImageNet 2012 challenge by a large margin. It is similar to the LeNet-5 architecture but larger and deeper.\n",
        "It consists of 5 convolutional layers, 3 max-pooling layers, 2 normalization layers, 2 fully connected layers, and 1 softmax layer.\n",
        "Each convolutional layer consists of a convolution filter and a non-linear activation function called “ReLU”.\n",
        "AlexNet was the first architecture that used GPU to boost the training performance.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "OLa85F_pD0Yq",
        "outputId": "0b2810f9-01fb-4ad1-ef08-32e6cbca4b1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AlexNet is a convolutional neural network (CNN) architecture that was designed by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton. \\nIt won the ImageNet 2012 challenge by a large margin. It is similar to the LeNet-5 architecture but larger and deeper. \\nIt consists of 5 convolutional layers, 3 max-pooling layers, 2 normalization layers, 2 fully connected layers, and 1 softmax layer. \\nEach convolutional layer consists of a convolution filter and a non-linear activation function called “ReLU”. \\nAlexNet was the first architecture that used GPU to boost the training performance.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2) Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance.\n",
        "'''The success of AlexNet is mostly attributed to its ability to leverage GPU for training and being able to train these huge numbers of parameters.\n",
        "AlexNet made revolutionary implementation on ConvNets that continues nowadays, such as ReLU and dropout.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ePuzGaD0D2yp",
        "outputId": "64d84e7f-ab05-4e2a-fb77-3bd64d136eb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The success of AlexNet is mostly attributed to its ability to leverage GPU for training and being able to train these huge numbers of parameters. \\nAlexNet made revolutionary implementation on ConvNets that continues nowadays, such as ReLU and dropout.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3) Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet.\n",
        "'''In AlexNet, convolutional layers are used for feature extraction.\n",
        "Pooling layers are used to progressively reduce the spatial size of the representation, to reduce the number of parameters and amount of computation in the network, and hence to also control overfitting.\n",
        "Fully connected layers are used to map the extracted features into final output, such as classification.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "_eVDpV-nE76p",
        "outputId": "59f98c1b-00ab-45c9-be5c-7adedac453e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In AlexNet, convolutional layers are used for feature extraction. \\nPooling layers are used to progressively reduce the spatial size of the representation, to reduce the number of parameters and amount of computation in the network, and hence to also control overfitting. \\nFully connected layers are used to map the extracted features into final output, such as classification.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8aXuvVxMWTU",
        "outputId": "4dd7d1ad-f8ab-49f8-d14a-994f178bd263"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4) Implement AlexNet using a deep learning framework of your choice and evaluate its performance on a dataset of your choice.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "# Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "x, y = oxflower17.load_data()\n",
        "x_train = x.astype('float32') / 255.0\n",
        "y_train = to_categorical(y, num_classes=17)\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Habl-_FO4A",
        "outputId": "f1d5672a-ea40-4f37-9d09-22a78fb850a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 54, 54, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 26, 26, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 384)       885120    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 384)       0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 384)         1327488   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 384)        1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 6, 6, 256)         884992    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              4198400   \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4096)             16384     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 17)                69649     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 17)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,834,833\n",
            "Trainable params: 24,815,697\n",
            "Non-trainable params: 19,136\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}