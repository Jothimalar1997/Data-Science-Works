{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "rFS85nypuTS8",
        "outputId": "7670d1d4-6ab7-47a2-c332-2e4ccceabcfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Anomaly detection is a process that identifies data points, events, or observations that deviate significantly from the normal behavior or pattern in a dataset. \\nIt can be used to identify potential incidents, opportunities, or errors in various domains. \\nAnomalous data can indicate critical incidents such as technical glitches or potential opportunities such as changes in consumer behavior. \\nAnomaly detection can involve data science tasks like classification, regression, and clustering1. It can also be referred to as outlier detection or novelty detection.\\nThe purpose of anomaly detection is to identify unusual patterns that do not conform to expected behavior. \\nThis can help organizations detect and prevent fraud, identify network intrusions, monitor system performance, and more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "## Q1. What is anomaly detection and what is its purpose?\n",
        "'''Anomaly detection is a process that identifies data points, events, or observations that deviate significantly from the normal behavior or pattern in a dataset. \n",
        "It can be used to identify potential incidents, opportunities, or errors in various domains. \n",
        "Anomalous data can indicate critical incidents such as technical glitches or potential opportunities such as changes in consumer behavior. \n",
        "Anomaly detection can involve data science tasks like classification, regression, and clustering1. It can also be referred to as outlier detection or novelty detection.\n",
        "The purpose of anomaly detection is to identify unusual patterns that do not conform to expected behavior. \n",
        "This can help organizations detect and prevent fraud, identify network intrusions, monitor system performance, and more.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. What are the key challenges in anomaly detection?\n",
        "'''Some of the key challenges in anomaly detection include modeling normal behavior to provide the correct context, separating noise from real outliers, and training sample sizes. \n",
        "Another challenge is that there is no single solution for anomaly detection; depending on the nature and characteristics of your data, you may need to use various algorithms or a hybrid approach. \n",
        "Once you have chosen or developed an anomaly detection algorithm, validating and tuning it using appropriate data and metrics can be quite a challenge due to the lack of labeled data. \n",
        "Anomalies will skew the baseline, which will affect the overall accuracy of the model.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TrnYSsRcupzk",
        "outputId": "aeade3b2-be4f-4c20-bfcb-7220bc8c1918"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some of the key challenges in anomaly detection include modeling normal behavior to provide the correct context, separating noise from real outliers, and training sample sizes. \\nAnother challenge is that there is no single solution for anomaly detection; depending on the nature and characteristics of your data, you may need to use various algorithms or a hybrid approach. \\nOnce you have chosen or developed an anomaly detection algorithm, validating and tuning it using appropriate data and metrics can be quite a challenge due to the lack of labeled data. \\nAnomalies will skew the baseline, which will affect the overall accuracy of the model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
        "'''Supervised anomaly detection requires labeled data that indicates if a record is normal or abnormal. \n",
        "In contrast, unsupervised anomaly detection is the process of identifying unexpected items or events in unlabeled datasets, which differ from the norm. \n",
        "It does not require any prior knowledge about the anomalies, but assumes that they are rare and make up a small percentage of the data. \n",
        "It involves modeling the normal data distribution and defining a measurement to classify samples as anomalous or normal.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "n3CKcEjyu5ga",
        "outputId": "6118b25a-a693-421c-db94-54be4d2af313"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Supervised anomaly detection requires labeled data that indicates if a record is normal or abnormal. \\nIn contrast, unsupervised anomaly detection is the process of identifying unexpected items or events in unlabeled datasets, which differ from the norm. \\nIt does not require any prior knowledge about the anomalies, but assumes that they are rare and make up a small percentage of the data. \\nIt involves modeling the normal data distribution and defining a measurement to classify samples as anomalous or normal.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4. What are the main categories of anomaly detection algorithms?\n",
        "'''There are several categories of anomaly detection algorithms. Some of the main categories include statistical methods, clustering-based methods, nearest neighbor-based methods, and spectral methods.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OsxMEu_HvHzC",
        "outputId": "7091e2c2-3699-4d22-b5cd-b9b61423990a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several categories of anomaly detection algorithms. Some of the main categories include statistical methods, clustering-based methods, nearest neighbor-based methods, and spectral methods.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
        "'''Distance-based anomaly detection methods make the following assumptions:\n",
        "1) Anomalies are far from their nearest neighbors.\n",
        "2) Normal data points are close to a dense region of data points.\n",
        "3) The distance metric used is appropriate for the problem at hand.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "5bDyZ55jvSeL",
        "outputId": "5ffdb93a-84c1-42e8-b823-3b68b81fde9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Distance-based anomaly detection methods make the following assumptions:\\n1) Anomalies are far from their nearest neighbors.\\n2) Normal data points are close to a dense region of data points.\\n3) The distance metric used is appropriate for the problem at hand.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q6. How does the LOF algorithm compute anomaly scores?\n",
        "'''The Local Outlier Factor (LOF) algorithm computes anomaly scores by comparing the density of a given data point to the density of its neighbors. \n",
        " computes the local density deviation of a given data point with respect to its neighbors and considers as outliers the samples that have a substantially lower density than their neighbors.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "mPLeTgjwvb4k",
        "outputId": "8cf03afb-082e-40a7-c0f6-90dfb55c6bc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Local Outlier Factor (LOF) algorithm computes anomaly scores by comparing the density of a given data point to the density of its neighbors. \\n computes the local density deviation of a given data point with respect to its neighbors and considers as outliers the samples that have a substantially lower density than their neighbors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q7. What are the key parameters of the Isolation Forest algorithm?\n",
        "'''The key parameters of the Isolation Forest algorithm are:\n",
        "1) n_estimators: The number of base estimators or trees in the ensemble, i.e. the number of trees that will get built in the forest.\n",
        "2) max_samples: The number of samples to draw from X to train each base estimator.\n",
        "3) contamination: The proportion of outliers in the dataset.\n",
        "4) max_features: The number of features to draw from X to train each base estimator.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "PTNI65L0vo4m",
        "outputId": "9a9598eb-2b45-4b98-f9cc-817a6e6bab81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The key parameters of the Isolation Forest algorithm are:\\n1) n_estimators: The number of base estimators or trees in the ensemble, i.e. the number of trees that will get built in the forest.\\n2) max_samples: The number of samples to draw from X to train each base estimator.\\n3) contamination: The proportion of outliers in the dataset.\\n4) max_features: The number of features to draw from X to train each base estimator.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
        "'''The anomaly score of a data point is calculated as the average of the ratio of the local reachability density of a sample and those of its k-nearest neighbors. \n",
        "In this case, the data point has only 2 neighbors of the same class within a radius of 0.5. \n",
        "Therefore, it is not possible to calculate the anomaly score using KNN with K=10 as there are not enough neighbors to calculate the score.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "USANMGHAv1Yr",
        "outputId": "87491cf4-6ad2-4872-e5aa-f898f63531d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The anomaly score of a data point is calculated as the average of the ratio of the local reachability density of a sample and those of its k-nearest neighbors. \\nIn this case, the data point has only 2 neighbors of the same class within a radius of 0.5. \\nTherefore, it is not possible to calculate the anomaly score using KNN with K=10 as there are not enough neighbors to calculate the score.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
        "'''The anomaly score s(x) of an observation x is computed by normalizing the path length h(x) as follows:\n",
        "s(x) = 2 − E[h(x)] / c(n)\n",
        "where E[h(x)] is the average path length over all isolation trees in the isolation forest, and c(n) is the average path length of unsuccessful searches in a binary search tree of n observations.\n",
        "Therefore, if you have 100 trees and a dataset of 3000 data points, the average path length of the trees is 5.0 and \n",
        "you want to calculate the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees, then:\n",
        "s(x) = 2 − E[5.0] / c(3000)\n",
        "The value of c(3000) can be calculated as follows:\n",
        "c(3000) = 2 * (log(3000 - 1) + 0.5772156649) - (2 * (3000 - 1) / 3000)\n",
        "Therefore:\n",
        "s(x) = 2 − E[5.0] / (2 * (log(3000 - 1) + 0.5772156649) - (2 * (3000 - 1) / 3000))\n",
        "s(x) = 0.9997'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "aNQ8lipgwMCu",
        "outputId": "a2549d4a-dcac-4d52-8d61-fd5b900d6673"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The anomaly score s(x) of an observation x is computed by normalizing the path length h(x) as follows:\\ns(x) = 2 − E[h(x)] / c(n)\\nwhere E[h(x)] is the average path length over all isolation trees in the isolation forest, and c(n) is the average path length of unsuccessful searches in a binary search tree of n observations.\\nTherefore, if you have 100 trees and a dataset of 3000 data points, the average path length of the trees is 5.0 and \\nyou want to calculate the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees, then:\\ns(x) = 2 − E[5.0] / c(3000)\\nThe value of c(3000) can be calculated as follows:\\nc(3000) = 2 * (log(3000 - 1) + 0.5772156649) - (2 * (3000 - 1) / 3000)\\nTherefore:\\ns(x) = 2 − E[5.0] / (2 * (log(3000 - 1) + 0.5772156649) - (2 * (3000 - 1) / 3000))\\ns(x) = 0.9997'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}