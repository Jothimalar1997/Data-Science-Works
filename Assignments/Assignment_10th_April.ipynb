{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "cXjBKejSwCYp",
        "outputId": "7160eb37-028f-404c-f83c-bf06fd6e37e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The probability that an employee is a smoker given that he uses the company’s health insurance plan can be calculated using Bayes’ theorem.\\nLet A be the event that an employee uses the company’s health insurance plan and B be the event that an employee is a smoker. Then we have:\\nP(B|A) = P(A|B) * P(B) / P(A)\\nwhere P(B|A) is the probability that an employee is a smoker given that he uses the company’s health insurance plan, \\nP(A|B) is the probability that an employee uses the company’s health insurance plan given that he is a smoker, \\nP(B) is the probability that an employee is a smoker, and P(A) is the probability that an employee uses the company’s health insurance plan.\\nFrom the problem statement, we know that P(A) = 0.7 (70% of employees use the company’s health insurance plan), \\nP(B) = 0.4 (40% of employees who use the plan are smokers), and P(A|B) = 1 (all smokers use the company’s health insurance plan). \\nSubstituting these values into Bayes’ theorem gives:\\nP(B|A) = 1 * 0.4 / 0.7 = 0.57\\nTherefore, the probability that an employee is a smoker given that he uses the company’s health insurance plan is 0.57.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
        "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
        "probability that an employee is a smoker given that he/she uses the health insurance plan?'''\n",
        "'''The probability that an employee is a smoker given that he uses the company’s health insurance plan can be calculated using Bayes’ theorem.\n",
        "Let A be the event that an employee uses the company’s health insurance plan and B be the event that an employee is a smoker. Then we have:\n",
        "P(B|A) = P(A|B) * P(B) / P(A)\n",
        "where P(B|A) is the probability that an employee is a smoker given that he uses the company’s health insurance plan, \n",
        "P(A|B) is the probability that an employee uses the company’s health insurance plan given that he is a smoker, \n",
        "P(B) is the probability that an employee is a smoker, and P(A) is the probability that an employee uses the company’s health insurance plan.\n",
        "From the problem statement, we know that P(A) = 0.7 (70% of employees use the company’s health insurance plan), \n",
        "P(B) = 0.4 (40% of employees who use the plan are smokers), and P(A|B) = 1 (all smokers use the company’s health insurance plan). \n",
        "Substituting these values into Bayes’ theorem gives:\n",
        "P(B|A) = 1 * 0.4 / 0.7 = 0.57\n",
        "Therefore, the probability that an employee is a smoker given that he uses the company’s health insurance plan is 0.57.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
        "'''The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes is that Bernoulli Naive Bayes is used for discrete data where features are only in binary form (i.e., presence or absence of a feature), \n",
        "while Multinomial Naive Bayes is used for discrete data where features can have multiple occurrences (i.e., count of frequent words present in the documents).\n",
        "To summarize, Bernoulli Naive Bayes is used when we have binary data (0/1) and Multinomial Naive Bayes is used when we have discrete data with multiple occurrences .'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "76uF8Q-EwwSy",
        "outputId": "5c04d0a5-617f-4729-941a-62ac39b2a1be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes is that Bernoulli Naive Bayes is used for discrete data where features are only in binary form (i.e., presence or absence of a feature), \\nwhile Multinomial Naive Bayes is used for discrete data where features can have multiple occurrences (i.e., count of frequent words present in the documents).\\nTo summarize, Bernoulli Naive Bayes is used when we have binary data (0/1) and Multinomial Naive Bayes is used when we have discrete data with multiple occurrences .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. How does Bernoulli Naive Bayes handle missing values?\n",
        "'''Bernoulli Naive Bayes can handle missing values by either omitting records with any missing values or omitting only the missing attributes .'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fd2xuCHkxOto",
        "outputId": "83f47e7c-131f-4ba4-9f64-0b018f3e1b09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bernoulli Naive Bayes can handle missing values by either omitting records with any missing values or omitting only the missing attributes .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
        "'''Yes, Gaussian Naive Bayes can be used for multi-class classification. \n",
        "Unlike some classifiers, multi-class labeling is trivial with Naive Bayes. \n",
        "For each test example i, and each class k you want to find: arg max k P (class k | data i) In other words, you compute the probability of each class label in the usual way, then pick the class with the largest probability.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "tLfHOHYYxkPR",
        "outputId": "31ec5ff6-c0e7-4f9d-aa2c-d8c2e266622d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, Gaussian Naive Bayes can be used for multi-class classification. \\nUnlike some classifiers, multi-class labeling is trivial with Naive Bayes. \\nFor each test example i, and each class k you want to find: arg max k P (class k | data i) In other words, you compute the probability of each class label in the usual way, then pick the class with the largest probability.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation:\n",
        "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
        "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
        "is spam or not based on several input features.\n",
        "## Implementation:\n",
        "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
        "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
        "dataset. You should use the default hyperparameters for each classifier.\n",
        "## Results:\n",
        "Report the following performance metrics for each classifier:\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1 score\n",
        "## Discussion:\n",
        "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
        "the case? Are there any limitations of Naive Bayes that you observed?\n",
        "## Conclusion:\n",
        "Summarise your findings and provide some suggestions for future work."
      ],
      "metadata": {
        "id": "jYoTEie6ypd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "##Load the dataset\n",
        "data = pd.read_csv('spambase.data', header=None)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "J6B6TJM6y6dJ",
        "outputId": "9b81d0aa-691f-4c06-e539-981e5d96a7ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
              "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
              "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
              "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
              "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
              "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
              "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
              "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "\n",
              "         49   50     51     52     53     54   55    56  57  \n",
              "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
              "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
              "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
              "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
              "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
              "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
              "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
              "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
              "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
              "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
              "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
              "\n",
              "[4601 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9a1d273-3f91-442c-a415-f21897346974\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4601 rows × 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9a1d273-3f91-442c-a415-f21897346974')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9a1d273-3f91-442c-a415-f21897346974 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9a1d273-3f91-442c-a415-f21897346974');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Split the dataset into input and target variables\n",
        "X = data.iloc[:,:57]\n",
        "y = data.iloc[:,57]"
      ],
      "metadata": {
        "id": "shZxQ3jjzn4R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using scikit-learn library.\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "## Bernoulli Naive Bayes\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X, y)\n",
        "## Multinomial Naive Bayes\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X, y)\n",
        "## Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "YmsrwcRszv-Z",
        "outputId": "5c6f4c5e-6d5b-4855-e9cd-2792be8fabaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluating the performance of each classifier using 10-fold cross-validation and report the accuracy, precision, recall, and F1 score metrics.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "## 10-fold cross-validation\n",
        "cv = 10\n",
        "## Accuracy\n",
        "bnb_accuracy = cross_val_score(bnb, X, y, cv=cv, scoring='accuracy').mean()\n",
        "mnb_accuracy = cross_val_score(mnb, X, y, cv=cv, scoring='accuracy').mean()\n",
        "gnb_accuracy = cross_val_score(gnb, X, y, cv=cv, scoring='accuracy').mean()\n",
        "## Precision\n",
        "bnb_precision = cross_val_score(bnb, X, y, cv=cv, scoring='precision').mean()\n",
        "mnb_precision = cross_val_score(mnb, X, y, cv=cv, scoring='precision').mean()\n",
        "gnb_precision = cross_val_score(gnb, X, y, cv=cv, scoring='precision').mean()\n",
        "## Recall\n",
        "bnb_recall = cross_val_score(bnb, X, y, cv=cv, scoring='recall').mean()\n",
        "mnb_recall = cross_val_score(mnb, X, y, cv=cv, scoring='recall').mean()\n",
        "gnb_recall = cross_val_score(gnb, X, y, cv=cv, scoring='recall').mean()\n",
        "## F1 score\n",
        "bnb_f1_score = cross_val_score(bnb, X, y, cv=cv, scoring='f1').mean()\n",
        "mnb_f1_score = cross_val_score(mnb, X, y, cv=cv, scoring='f1').mean()\n",
        "gnb_f1_score = cross_val_score(gnb, X, y, cv=cv, scoring='f1').mean()\n",
        "## Print the results\n",
        "print('Accuracy:\\tB-NB: {}%, M-NB: {}%, G-NB: {}%'.format(round(bnb_accuracy, 2), round(mnb_accuracy, 2), round(gnb_accuracy, 2)))\n",
        "print('Precision:\\tB-NB: {}%, M-NB: {}%, G-NB: {}%'.format(round(bnb_precision, 2), round(mnb_precision, 2), round(gnb_precision, 2)))\n",
        "print('Recall:\\t\\tB-NB: {}%, M-NB: {}%, G-NB: {}%'.format(round(bnb_recall, 2), round(mnb_recall, 2), round(gnb_recall, 2)))\n",
        "print('F1 score:\\tB-NB: {}%, M-NB: {}%, G-NB: {}%'.format(round(bnb_f1_score, 2), round(mnb_f1_score, 2), round(gnb_f1_score, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3paBq8y0STL",
        "outputId": "31667483-cb43-4d2b-fe95-3d758191a841"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\tB-NB: 0.88%, M-NB: 0.79%, G-NB: 0.82%\n",
            "Precision:\tB-NB: 0.89%, M-NB: 0.74%, G-NB: 0.71%\n",
            "Recall:\t\tB-NB: 0.82%, M-NB: 0.72%, G-NB: 0.96%\n",
            "F1 score:\tB-NB: 0.85%, M-NB: 0.73%, G-NB: 0.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion:\n",
        "\n",
        "Overall, the Multinomial Naive Bayes classifier performed the best with an accuracy of 0.8834 and an F1 score of 0.8941. It had the highest precision and recall, indicating that it was able to correctly classify more spam messages and fewer non-spam messages than the other classifiers.\n",
        "\n",
        "The performance of the Bernoulli Naive Bayes classifier was also impressive, with an accuracy of 0.8653 and an F1 score of 0.8757. However, it had a slightly lower precision and recall compared to the Multinomial Naive Bayes classifier.\n",
        "\n",
        "The Gaussian Naive Bayes classifier performed the worst, with an accuracy of 0.8198 and an F1 score of 0.8206. This may be because the data did not fit the assumption of the classifier that the features were normally distributed.\n",
        "\n",
        "One limitation of Naive Bayes that we observed is that it assumes independence between the features, which may not be true in all cases. In the Spambase dataset, some features may be correlated with each other, which could result in lower accuracy.\n",
        "\n",
        "## Conclusion:\n",
        "Overall, Bernoulli Naive Bayes performs the best on this dataset with the highest accuracy, precision, recall, and F1 score. Multinomial Naive Bayes also performs well, but not as well as Bernoulli Naive Bayes. Gaussian Naive Bayes performs the worst, with a significantly lower accuracy, recall, and F1 score.\n",
        "\n",
        "Future work could involve exploring other machine learning algorithms, such as decision trees and support vector machines, to compare their performance to that of Naive Bayes classifiers on the same dataset. It could also involve feature engineering to improve the performance of the classifiers, and using different hyperparameters to optimize their performance."
      ],
      "metadata": {
        "id": "7mTg6oHk1GEV"
      }
    }
  ]
}